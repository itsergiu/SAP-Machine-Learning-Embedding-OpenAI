{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7194810",
   "metadata": {},
   "source": [
    "### SAP Machine Learning Embedding in OpenAI - step 04\n",
    "##### Author: Sergiu Iatco. May, 2023\n",
    "https://people.sap.com/iatco.sergiu <br>\n",
    "https://www.linkedin.com/in/sergiuiatco/ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbbb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class collect_text():\n",
    "    def __init__(self, mask_ext = None):\n",
    "        if mask_ext==None:\n",
    "            self.mask_ext = '.txt'\n",
    "        else:\n",
    "            self.mask_ext = mask_ext\n",
    "        \n",
    "    def open_html(self, html_file, encoding_read = None):\n",
    "\n",
    "        if encoding_read==None:\n",
    "            encoding_read = 'utf-8'\n",
    "\n",
    "        with open(html_file, encoding=encoding_read) as f:\n",
    "            html_content = f.read()\n",
    "        \n",
    "        return html_content\n",
    "    \n",
    "    def html_to_text(self, html_content):\n",
    "\n",
    "        soup = BeautifulSoup(html_content)\n",
    "        text = soup.get_text()\n",
    "        text_content = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "        return text_content\n",
    "\n",
    "    def html_to_text_file(self, html_file, path_save = None, content = False, verbose = 0, encoding_read=None, \\\n",
    "                           encoding_write = None):\n",
    "        \n",
    "              \n",
    "        html_content = self.open_html(html_file, encoding_read = encoding_read)\n",
    "        text_content = self.html_to_text(html_content)\n",
    "\n",
    "        if encoding_write==None:\n",
    "            encoding_write = 'utf-8'\n",
    "\n",
    "        filename_path = os.path.split(html_file)[0] \n",
    "        filename_with_ext = os.path.split(html_file)[1]  #filename with ext & w/o path\n",
    "        filename_ext_txt = os.path.splitext(filename_with_ext)[0] + self.mask_ext\n",
    "        \n",
    "        if path_save!= None:\n",
    "            txt_file = os.path.join(path_save, filename_path, filename_ext_txt)\n",
    "            \n",
    "            path_save_subdir_source = os.path.split(txt_file)[0] # file path\n",
    "            \n",
    "            if not os.path.exists(path_save_subdir_source):\n",
    "                os.makedirs(path_save_subdir_source)\n",
    "            \n",
    "            print(f\"path_save: {path_save}\")\n",
    "            print(f\"path_save_subdir_source: {path_save_subdir_source}\")\n",
    "                \n",
    "        else:\n",
    "            txt_file = os.path.join(filename_path, filename_ext_txt)\n",
    "    \n",
    "        with open(txt_file, 'w', encoding=encoding_write) as f:\n",
    "            f.write(text_content)\n",
    "\n",
    "        if verbose == 1:\n",
    "            print(f\"Source     : {html_file}\")\n",
    "            print(f\"Destination: {txt_file}\")\n",
    "        \n",
    "        if os.path.exists(txt_file):\n",
    "            print(\"File conversion complete and save!\")\n",
    "        else:\n",
    "            print(\"File was not saved!\")\n",
    "        \n",
    "        if content == True:\n",
    "            return txt_file\n",
    "    \n",
    "    def html_path_to_text(self, repo_path = None, path_save = None, encoding_read = None, encoding_write = None, verbose = 0):\n",
    "        # verbose: 0 - Complete message | 1 - Source file & Saved file\n",
    "        name_filter = \"**/*.html\"\n",
    "        if repo_path==None:\n",
    "            repo_path = ''\n",
    "        \n",
    "        repo_path_lib = pathlib.Path(repo_path)\n",
    "        document_files = list(repo_path_lib.glob(name_filter))\n",
    "        \n",
    "        for html_file in document_files:\n",
    "        \n",
    "            self.html_to_text_file(html_file, path_save = path_save, content = False, verbose = verbose, \\\n",
    "                                   encoding_read=None, encoding_write = None)\n",
    "       \n",
    "        print(f\"List conversion complete! Files: {len(document_files)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ef4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "class clean_data():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tail_trimm(self, path,  tail_del_n = 3, file_extension = '.txt', verbose = 0):\n",
    "        path_lib = pathlib.Path(path)\n",
    "        path_lib_files = list(path_lib.glob(f\"**/*{file_extension}\"))\n",
    "        files_processed_n = 0\n",
    "        encoding_read = 'utf-8'\n",
    "\n",
    "        for file in path_lib_files:\n",
    "            with open(file, 'r', encoding = encoding_read,) as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            modified_lines = lines[:-tail_del_n]\n",
    "\n",
    "            with open(file, 'w', encoding = encoding_read) as f:\n",
    "                f.writelines(modified_lines)\n",
    "            if verbose == 1:\n",
    "                print(f\"File processed: {file}\")\n",
    "\n",
    "        print(f\"Files processed: {len(path_lib_files)}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6a1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1 convert html_file to text and save from folder to path_save\n",
    "# ct = collect_text(mask_ext = '.txt')\n",
    "# html_file = \"html_files_test/ipynb_source_test/example notebook v1.html\"\n",
    "# path_save = 'html_files_test_txt'\n",
    "# ct.html_to_text_file(html_file = html_file, path_save = path_save, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5575143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 2 convert html repo_path to text and save in same folder\n",
    "# repo_path = 'html_files_test/'\n",
    "# cl_to_text = collect_text(mask_ext = '.txt')\n",
    "# cl_to_text.html_path_to_text(repo_path = repo_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5590d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 3 convert html from repo_path to text and save in path_save\n",
    "# repo_path = 'html_files_test/'\n",
    "# path_save = 'html_files_test_path_txt'\n",
    "# cl_to_text = collect_text(mask_ext = '.txt')\n",
    "# cl_to_text.html_path_to_text(repo_path = repo_path, path_save = path_save, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b53f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source     : llama_challenge\\html_challenge\\understanding_metrics_blog.html\n",
      "Destination: llama_challenge\\html_challenge\\understanding_metrics_blog.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\html_challenge\\challenge_20221107.html\n",
      "Destination: llama_challenge\\html_challenge\\challenge_20221107.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\html_challenge\\challenge_20221128.html\n",
      "Destination: llama_challenge\\html_challenge\\challenge_20221128.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\html_challenge\\challenge_20221222.html\n",
      "Destination: llama_challenge\\html_challenge\\challenge_20221222.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\html_challenge\\hana_ml.dataframe.html\n",
      "Destination: llama_challenge\\html_challenge\\hana_ml.dataframe.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\html_challenge\\hana_ml.algorithms.pal.trees.HybridGradientBoostingClassifier.html\n",
      "Destination: llama_challenge\\html_challenge\\hana_ml.algorithms.pal.trees.HybridGradientBoostingClassifier.txt\n",
      "File conversion complete and save!\n",
      "List conversion complete! Files: 6\n"
     ]
    }
   ],
   "source": [
    "# Convert html from repo_path in txt and save in same folder\n",
    "repo_path1 = 'llama_challenge/html_challenge/'\n",
    "\n",
    "cl_to_text = collect_text(mask_ext = '.txt')\n",
    "cl_to_text.html_path_to_text(repo_path = repo_path1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779139e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source     : llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\10 Connectivity Check.html\n",
      "Destination: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\10 Connectivity Check.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\20 Data upload.html\n",
      "Destination: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\20 Data upload.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\PAL Tutorial - Unified Classification Hybrid Gradient Boosting - PredictiveQuality Example.html\n",
      "Destination: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\PAL Tutorial - Unified Classification Hybrid Gradient Boosting - PredictiveQuality Example.txt\n",
      "File conversion complete and save!\n",
      "Source     : llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\Upload and explore Employee Churn data.html\n",
      "Destination: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\Upload and explore Employee Churn data.txt\n",
      "File conversion complete and save!\n",
      "List conversion complete! Files: 4\n"
     ]
    }
   ],
   "source": [
    "# Convert html from repo_path in txt and save in same folder\n",
    "repo_path2 = \"llama_challenge//ipynb_hana_ml_samples//Python-API//usecase-examples//sapcommunity-hanaml-challenge\"\n",
    "cl_to_text = collect_text(mask_ext = '.txt')\n",
    "cl_to_text.html_path_to_text(repo_path = repo_path2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b183f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source     : llama_challenge\\ipynb_blog\\SAP HANA ML challendge - CHURN  v2.3 max.html\n",
      "Destination: llama_challenge\\ipynb_blog\\SAP HANA ML challendge - CHURN  v2.3 max.txt\n",
      "File conversion complete and save!\n",
      "List conversion complete! Files: 1\n"
     ]
    }
   ],
   "source": [
    "# Convert html from repo_path in txt and save in same folder\n",
    "repo_path3 = 'llama_challenge/ipynb_blog/'\n",
    "cl_to_text = collect_text(mask_ext = '.txt')\n",
    "repo_path = 'llama_challenge/html_challenge/'\n",
    "cl_to_text.html_path_to_text(repo_path = repo_path3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bdbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def list_ipynb(repo_path, extension):\n",
    "    name_filter = f\"**/*.{extension}\"\n",
    "    repo_path_lib = pathlib.Path(repo_path)\n",
    "    files = list(repo_path_lib.glob(name_filter))\n",
    "    for file in files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d83df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_challenge/html_challenge/\n",
      "\n",
      "llama_challenge\\html_challenge\\understanding_metrics_blog.txt\n",
      "llama_challenge\\html_challenge\\challenge_20221107.txt\n",
      "llama_challenge\\html_challenge\\challenge_20221128.txt\n",
      "llama_challenge\\html_challenge\\challenge_20221222.txt\n",
      "llama_challenge\\html_challenge\\hana_ml.dataframe.txt\n",
      "llama_challenge\\html_challenge\\hana_ml.algorithms.pal.trees.HybridGradientBoostingClassifier.txt\n"
     ]
    }
   ],
   "source": [
    "print(repo_path1)\n",
    "print()\n",
    "list_ipynb(repo_path1, \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6c838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_challenge//ipynb_hana_ml_samples//Python-API//usecase-examples//sapcommunity-hanaml-challenge\n",
      "\n",
      "llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\readme.txt\n",
      "llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\10 Connectivity Check.txt\n",
      "llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\20 Data upload.txt\n",
      "llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\PAL Tutorial - Unified Classification Hybrid Gradient Boosting - PredictiveQuality Example.txt\n",
      "llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\Upload and explore Employee Churn data.txt\n"
     ]
    }
   ],
   "source": [
    "print(repo_path2)\n",
    "print()\n",
    "list_ipynb(repo_path2, \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6052cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_challenge/ipynb_blog/\n",
      "\n",
      "llama_challenge\\ipynb_blog\\SAP HANA ML challendge - CHURN  v2.3 max.txt\n"
     ]
    }
   ],
   "source": [
    "print(repo_path3)\n",
    "print()\n",
    "list_ipynb(repo_path3, \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "559968de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clnd = clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c97316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed: llama_challenge\\html_challenge\\understanding_metrics_blog.txt\n",
      "File processed: llama_challenge\\html_challenge\\challenge_20221107.txt\n",
      "File processed: llama_challenge\\html_challenge\\challenge_20221128.txt\n",
      "File processed: llama_challenge\\html_challenge\\challenge_20221222.txt\n",
      "File processed: llama_challenge\\html_challenge\\hana_ml.dataframe.txt\n",
      "File processed: llama_challenge\\html_challenge\\hana_ml.algorithms.pal.trees.HybridGradientBoostingClassifier.txt\n",
      "Files processed: 6\n"
     ]
    }
   ],
   "source": [
    "clnd.tail_trimm(path = repo_path1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2a7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\readme.txt\n",
      "File processed: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\10 Connectivity Check.txt\n",
      "File processed: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\20 Data upload.txt\n",
      "File processed: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\PAL Tutorial - Unified Classification Hybrid Gradient Boosting - PredictiveQuality Example.txt\n",
      "File processed: llama_challenge\\ipynb_hana_ml_samples\\Python-API\\usecase-examples\\sapcommunity-hanaml-challenge\\Upload and explore Employee Churn data.txt\n",
      "Files processed: 5\n"
     ]
    }
   ],
   "source": [
    "clnd.tail_trimm(path = repo_path2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9aa9972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed: llama_challenge\\ipynb_blog\\SAP HANA ML challendge - CHURN  v2.3 max.txt\n",
      "Files processed: 1\n"
     ]
    }
   ],
   "source": [
    "clnd.tail_trimm(path = repo_path3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6925143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
